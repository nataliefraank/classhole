{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2247426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ff3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>self_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for cutting communications with my ex?</td>\n",
       "      <td>b3jk0h</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>No A-holes here</td>\n",
       "      <td>So me and my ex are both high school seniors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aita for thinking my girlfriend is dating me o...</td>\n",
       "      <td>b3jpqu</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Asshole</td>\n",
       "      <td>so, hi. on mobile, second time poster, english...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA For looking at my partners phone?</td>\n",
       "      <td>b3jsz3</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>Backstory: about 3 years ago my wife (fiancee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA for taking an unvaccinated child to a fri...</td>\n",
       "      <td>b3k5l9</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Asshole</td>\n",
       "      <td>Ok so here’s the thing. My friends daughter is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA when I give up on trying to follow the ru...</td>\n",
       "      <td>b3kbde</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>So. Lately, I've been extremely depressed. I'v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title post_id  over_18  \\\n",
       "0        AITA for cutting communications with my ex?  b3jk0h    False   \n",
       "1  aita for thinking my girlfriend is dating me o...  b3jpqu    False   \n",
       "2             AITA For looking at my partners phone?  b3jsz3    False   \n",
       "3  AITA for taking an unvaccinated child to a fri...  b3k5l9    False   \n",
       "4  AITA when I give up on trying to follow the ru...  b3kbde    False   \n",
       "\n",
       "       subreddit  link_flair_text  \\\n",
       "0  AmItheAsshole  No A-holes here   \n",
       "1  AmItheAsshole          Asshole   \n",
       "2  AmItheAsshole   Not the A-hole   \n",
       "3  AmItheAsshole          Asshole   \n",
       "4  AmItheAsshole   Not the A-hole   \n",
       "\n",
       "                                           self_text  \n",
       "0  So me and my ex are both high school seniors, ...  \n",
       "1  so, hi. on mobile, second time poster, english...  \n",
       "2  Backstory: about 3 years ago my wife (fiancee ...  \n",
       "3  Ok so here’s the thing. My friends daughter is...  \n",
       "4  So. Lately, I've been extremely depressed. I'v...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('../data_raw/ahole-small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f67740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_flair_text\n",
       "Not the A-hole     362237\n",
       "Asshole            101730\n",
       "No A-holes here     46261\n",
       "Everyone Sucks      28694\n",
       "Not enough info     13530\n",
       "UPDATE               6062\n",
       "not the a-hole       4768\n",
       "TL;DR                3808\n",
       "asshole              1803\n",
       "META                 1287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data quality issues\n",
    "df.isnull().sum()\n",
    "df['post_id'].nunique()\n",
    "df['title'].nunique()\n",
    "df['over_18'].value_counts()\n",
    "df['subreddit'].value_counts()\n",
    "df['link_flair_text'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c00caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter out rows with invalid self_text\n",
    "# Keep only rows with valid, non-empty text content\n",
    "\n",
    "invalid_text_mask = (\n",
    "    df['self_text'].isna() | \n",
    "    (df['self_text'] == '') | \n",
    "    (df['self_text'] == '[removed]') | \n",
    "    (df['self_text'] == '[deleted]')\n",
    ")\n",
    "\n",
    "df_clean = df[~invalid_text_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebbe2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter to binary classification categories\n",
    "# Keep only \"Not the A-hole\" and \"Asshole\" for training\n",
    "main_categories_binary = ['Not the A-hole', 'Asshole']\n",
    "df_binary = df_clean[df_clean['link_flair_text'].isin(main_categories_binary)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf3a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create binary labels for classification\n",
    "def create_binary_label(flair_text):\n",
    "    \"\"\"Convert flair text to binary label: 0 = Not the A-hole, 1 = Asshole\"\"\"\n",
    "    if flair_text == 'Not the A-hole':\n",
    "        return 0\n",
    "    elif flair_text == 'Asshole':\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_binary['label'] = df_binary['link_flair_text'].apply(create_binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16519e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>self_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1359557</th>\n",
       "      <td>WIBTA if I tell people to pick up their garbage</td>\n",
       "      <td>caagbv</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>So in accordance with the increasing awareness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165415</th>\n",
       "      <td>AITA for not taking the full blame for ruining...</td>\n",
       "      <td>ueau1g</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>My aunt is going for surgery today, so yesterd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18601</th>\n",
       "      <td>AITA for telling my 26 year old daughter to gr...</td>\n",
       "      <td>gc3nhk</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Asshole</td>\n",
       "      <td>My daughter takes commissions from people some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176311</th>\n",
       "      <td>AITA for how I reacted towards a stranger who ...</td>\n",
       "      <td>qni2r3</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>I was in a local cafe waiting for a smoothie I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239853</th>\n",
       "      <td>AITA for not picking up my estranged husband a...</td>\n",
       "      <td>von20c</td>\n",
       "      <td>False</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>We do not get along. Days before the surgery, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title post_id  over_18  \\\n",
       "1359557    WIBTA if I tell people to pick up their garbage  caagbv    False   \n",
       "1165415  AITA for not taking the full blame for ruining...  ueau1g    False   \n",
       "18601    AITA for telling my 26 year old daughter to gr...  gc3nhk    False   \n",
       "1176311  AITA for how I reacted towards a stranger who ...  qni2r3    False   \n",
       "1239853  AITA for not picking up my estranged husband a...  von20c    False   \n",
       "\n",
       "             subreddit link_flair_text  \\\n",
       "1359557  AmItheAsshole  Not the A-hole   \n",
       "1165415  AmItheAsshole  Not the A-hole   \n",
       "18601    AmItheAsshole         Asshole   \n",
       "1176311  AmItheAsshole  Not the A-hole   \n",
       "1239853  AmItheAsshole  Not the A-hole   \n",
       "\n",
       "                                                 self_text  \n",
       "1359557  So in accordance with the increasing awareness...  \n",
       "1165415  My aunt is going for surgery today, so yesterd...  \n",
       "18601    My daughter takes commissions from people some...  \n",
       "1176311  I was in a local cafe waiting for a smoothie I...  \n",
       "1239853  We do not get along. Days before the surgery, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Create train/test splits\n",
    "\n",
    "def split(sample_data):\n",
    "    #Shuffle samples\n",
    "    randomized = sample_data.sample(frac=1)\n",
    "    num_samples = randomized.shape[0]\n",
    "    #percent training data\n",
    "    percent_training = .80\n",
    "    num_training = int(num_samples * percent_training)\n",
    "    train = randomized.iloc[:num_training]\n",
    "    test = randomized.iloc[num_training:, :]\n",
    "    X_train_bin = train.drop(\"label\", axis=1)\n",
    "    y_train_bin = train[\"label\"]\n",
    "    X_test_bin = test.drop(\"label\", axis=1)\n",
    "    y_test_bin = test[\"label\"]\n",
    "    return X_train_bin, y_train_bin, X_test_bin, y_test_bin\n",
    "\n",
    "X_train_bin, y_train_bin, X_test_bin, y_test_bin = split(df_binary)\n",
    "X_train_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f2c4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_raw/standardized/binary_test.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Export standardized datasets\n",
    "# Create output directory structure\n",
    "import os\n",
    "os.makedirs('../data_raw/standardized', exist_ok=True)\n",
    "\n",
    "# Export binary classification datasets\n",
    "def export_split(X, y, split_name):\n",
    "    \"\"\"Export a split to CSV\"\"\"\n",
    "    df_export = X.copy()\n",
    "    df_export['label'] = y\n",
    "    output_path = f'../data_raw/standardized/binary_{split_name}.csv'\n",
    "    df_export.to_csv(output_path, index=False)\n",
    "    return output_path\n",
    "\n",
    "# Export binary splits\n",
    "export_split(X_train_bin, y_train_bin, 'train')\n",
    "export_split(X_test_bin, y_test_bin, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "800b2aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_dataset': {'total_rows': 1767258, 'columns': ['title', 'post_id', 'over_18', 'subreddit', 'link_flair_text', 'self_text'], 'note': 'over_18 column removed from final datasets'}, 'cleaned_dataset': {'total_rows': 470534, 'rows_removed': 1296724, 'removal_reason': 'Missing/removed/deleted self_text'}, 'binary_dataset': {'total_rows': 382046, 'categories': ['Not the A-hole', 'Asshole'], 'train_rows': 305636, 'label_distribution': {'0 (Not the A-hole)': 243085, '1 (Asshole)': 62551}, 'note': 'Test set includes extra samples from \"No A-holes here\" and \"Everyone Sucks\" categories'}}\n"
     ]
    }
   ],
   "source": [
    "# Export summary statistics\n",
    "summary = {\n",
    "    'original_dataset': {\n",
    "        'total_rows': len(df),\n",
    "        'columns': df.columns.tolist(),\n",
    "        'note': 'over_18 column removed from final datasets'\n",
    "    },\n",
    "    'cleaned_dataset': {\n",
    "        'total_rows': len(df_clean),\n",
    "        'rows_removed': len(df) - len(df_clean),\n",
    "        'removal_reason': 'Missing/removed/deleted self_text'\n",
    "    },\n",
    "    'binary_dataset': {\n",
    "        'total_rows': len(df_binary),\n",
    "        'categories': ['Not the A-hole', 'Asshole'],\n",
    "        'train_rows': len(X_train_bin),\n",
    "        'label_distribution': {\n",
    "            '0 (Not the A-hole)': int((y_train_bin == 0).sum()),\n",
    "            '1 (Asshole)': int((y_train_bin == 1).sum())\n",
    "        },\n",
    "        'note': 'Test set includes extra samples from \"No A-holes here\" and \"Everyone Sucks\" categories'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
